#IMPORT LIBRARIES
import sys
from pathlib import Path, PureWindowsPath 
import glob
import os
from tqdm import tqdm
from shutil import copyfile
import pickle

import numpy as np
import tensorflow as tf
import keras
import cv2
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Conv2D, UpSampling2D, Lambda
from keras.models import Model, load_model
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras import backend as K
from keras import initializers, layers, models
from keras.preprocessing.image import ImageDataGenerator
from keras import callbacks
from keras import optimizers
import keras.applications as ka
from segmentation_models import Unet
from segmentation_models.backbones import get_preprocessing
from segmentation_models.utils import set_trainable
from subprocess import check_output
from keras.optimizers import Adam

from scipy import ndimage
import skimage
from skimage.transform import resize
from skimage.morphology import label
from skimage.color import rgb2gray
from sklearn.model_selection import train_test_split
from skimage.morphology import watershed, remove_small_holes, remove_small_objects, label
from skimage.feature import peak_local_max

home_path = Path.home()
sys.path.insert(0, str(home_path / 'project/code/sample'))

from config_script import *


final_dict = {}
folders = glob.glob(str(DATA_DIRECTORY.parent / 'test_new_images/Mar*' ))
idx = 0

for folder in tqdm(folders, total=len(folders)):
    os.chdir(folder)
    or_images = glob.glob(folder+'/*.TIF')
    or_images.sort()

    for image in or_images:
        im_name = image.split('/')[-1]
        im_name = im_name.replace('.TIF','')
        final_name= str(idx)+'.TIF'
        copyfile(image,str(DATA_DIRECTORY.parent / 'test_new_images/all_images/images' / final_name))
        final_dict[str(idx)] = im_name
        idx += 1
with open(str(DATA_DIRECTORY.parent / 'test_new_images/map.pkl'),'wb') as fp:
    pickle.dump(final_dict, fp)
with open(str(DATA_DIRECTORY.parent / 'test_new_images/map.txt'), 'w') as f:
    print(final_dict, file=f)


def mean_iou(y_true, y_pred):
    prec = []
    for t in np.arange(0.5, 1.0, 0.05):
        y_pred_ = tf.to_int32(y_pred > t)
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)
        K.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        prec.append(score)
    return K.mean(K.stack(prec), axis=0)

smooth = 1.

def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

def create_weighted_binary_crossentropy(zero_weight, one_weight):

    def weighted_binary_crossentropy(y_true, y_pred):

        # Original binary crossentropy (see losses.py):
        # K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)

        # Calculate the binary crossentropy
        b_ce = K.binary_crossentropy(y_true, y_pred)

        # Apply the weights
        weight_vector = y_true*one_weight + (1. - y_true)*zero_weight
        weighted_b_ce = weight_vector * b_ce

        # Return the mean error
        return K.mean(weighted_b_ce)

    return weighted_binary_crossentropy


WeightedLoss = create_weighted_binary_crossentropy(1, 2)    


model = load_model(str(MODEL_CHECKPOINTS / 'C0ResUnetAtlasYEluNorN16.h5'), custom_objects={'mean_iou': mean_iou, 'dice_coef': dice_coef, 'weighted_binary_crossentropy': WeightedLoss})


# model = load_model(str(MODEL_CHECKPOINTS / 'UnetRGB_crop_v9.h5'), custom_objects={'mean_iou': mean_iou, 'dice_coef': dice_coef})


IMAGES_PATH = DATA_DIRECTORY.parent / 'test_new_images/all_images/images/'

test_ids = check_output(["ls", IMAGES_PATH]).decode("utf8").split()
print(len(test_ids))


# file = open(str(DATA_DIRECTORY.parent / 'test_new_images/numero_conteggi_{}.txt'), 'w')

def counter(color = 'yellow', threshold = 0.55, small_holes = 600, small_objects = 300, size = 35,
           foot = 55):    
    th = str(threshold).replace('.','')
    file = open(str(DATA_DIRECTORY.parent / 'test_new_images/numero_conteggi_{}.txt'.format(th)), 'w')
    for name in test_ids:
        img = cv2.imread(str(IMAGES_PATH / name))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_or = img 
        img = img*1./255
        preds_test = model.predict(np.expand_dims(img,axis=0))
        preds_test_t = (preds_test > threshold).astype(np.uint8)
        number = int(name.split('.')[0])

        plt.figure(figsize=(15,10))

        iname = name.split('.')[0]
        print(str(final_dict[str(iname)]))

        labels_pred, nlabels_pred = ndimage.label(np.squeeze(preds_test_t))
        objs = ndimage.find_objects(labels_pred)

        measurements = []

        for ob in objs:
            measurements.append(((int((ob[0].stop - ob[0].start)/2)+ob[0].start), (int((ob[1].stop - ob[1].start)/2)+ob[1].start)))   

        processed = remove_small_holes(labels_pred, area_threshold=small_holes, connectivity=1,in_place=False, min_size=None)
        processed = remove_small_objects(processed, min_size=small_objects, connectivity=1, in_place=False)

        labels_bool = processed.astype(bool)

        distance = ndimage.distance_transform_edt(processed)
        maxi = ndimage.maximum_filter(distance, size=size, mode='constant')
        local_maxi = peak_local_max(maxi, indices=False, footprint=np.ones((foot, foot)),
                                    labels=labels_bool)
        
        if color == 'yellow':
            local_maxi = remove_small_objects(local_maxi, min_size=25, connectivity=1, in_place=False)
            
            
        markers = ndimage.label(local_maxi)[0]
        labels = watershed(-distance, markers, mask=labels_bool,watershed_line=True)
        labels = np.clip(labels,0,1)

        if number % 1 == 0:
            plt.subplot(1,2,1)
            plt.title("Prediction")
            plt.axis('off')
            plt.imshow(np.squeeze(img_or))
            plt.subplot(1,2,2)
            plt.title("Original")
            plt.axis('off')
            plt.imshow(np.squeeze(img_or))
            plt.contour(labels, [0.5], linewidhts=1.1, colors='orangered')
            

        labels_test_pred, nlabels_test_pred = ndimage.label(labels)

        print('Number of objects found: ' + str(nlabels_test_pred)+'\n\n')
        plt.savefig(str(DATA_DIRECTORY.parent / 'test_new_images/image_test_results_{}/{}.TIF'.format(th, str(final_dict[str(iname)]))))
        plt.show()
        file.write(str(final_dict[str(iname)])+'\t'+str(nlabels_test_pred)+'\n')
        
    file.close()


counter(color = 'yellow', threshold = 0.85, small_holes = 600, small_objects = 200, size = 30,
           foot = 40)
